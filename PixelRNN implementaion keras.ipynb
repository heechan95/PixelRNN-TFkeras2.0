{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31490,
     "status": "ok",
     "timestamp": 1572111044490,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "FwaM_08ESRRG",
    "outputId": "4a1838da-d39e-416a-9176-93aafa3fe802"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AbstractRNNCell\n",
    "from tensorflow.keras.layers import RNN\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R21uTgXWdcJS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EGGpIwh5E0R"
   },
   "source": [
    "If you want to check if op is run on GPU set following option to be true and run toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1uMmduDb6n8"
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_Pcww9S02Q6"
   },
   "source": [
    "You can skip the cell below since Eager Execution is by default enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4826,
     "status": "ok",
     "timestamp": 1571839966279,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "ov66Cb0nsZfF",
    "outputId": "8030f92b-363a-4969-d2fb-c083c9c7a77b"
   },
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbjqRp_n18ul"
   },
   "outputs": [],
   "source": [
    "def binarize(images):\n",
    "    return (np.random.uniform(size=images.shape) < images).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4531,
     "status": "ok",
     "timestamp": 1572111049207,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "vFYt5op8zdKH",
    "outputId": "2f967c38-a0ae-4f1c-b010-e33b086d5d8b"
   },
   "outputs": [],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "      pass\n",
    "\n",
    "def mnist_dataset(bsize=100, shuffle_buffer_size=1000):\n",
    "    (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "    x = binarize(np.array(x / 255.0, dtype=np.float32))\n",
    "    x = np.expand_dims(x, -1)\n",
    "    #import copy\n",
    "    #y = copy.deepcopy(x)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, Xval, Y, Yval = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    n_tr = X.shape[0]\n",
    "    n_te = Xval.shape[0]\n",
    "\n",
    "    #trds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    trds = tf.data.Dataset.from_tensor_slices((X, X))\n",
    "    #trds = trds.map(prepare_mnist_features_and_labels)\n",
    "    trds = trds.take(n_tr).shuffle(shuffle_buffer_size).batch(bsize)\n",
    "\n",
    "    #teds = tf.data.Dataset.from_tensor_slices((Xval, Yval))\n",
    "    teds = tf.data.Dataset.from_tensor_slices((Xval, Xval))\n",
    "    #trds = trds.map(prepare_mnist_features_and_labels)\n",
    "    teds = teds.take(n_te).shuffle(shuffle_buffer_size).batch(bsize)\n",
    "\n",
    "    return trds, teds\n",
    "\n",
    "train_dataset, val_dataset = mnist_dataset(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IloFNqJJSbxB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "'''\n",
    "grayscale은 쉬운데\n",
    "grayscale부터 해보자!\n",
    "rgb는 내생각에는\n",
    "utils에\n",
    "N, H, W, C --> N,H,W*C로 만들어야할듯\n",
    "반대 operation도! skew참조\n",
    "\n",
    "'''\n",
    "\n",
    "class MaskedConv2D(layers.Conv2D):\n",
    "    def __init__(self, *args, mask='B', n_channel=3, mono=False, **kargs):\n",
    "        super(MaskedConv2D,self).__init__(*args,**kargs)\n",
    "        self.mask_type = mask\n",
    "        self.mask = None\n",
    "        self.trainable=True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv2D, self).build(input_shape)\n",
    "        if self.data_format == 'channel_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape.dims[channel_axis].value is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                           'should be defined. Found `None`.')\n",
    "        input_dim = int(input_shape[channel_axis])\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "\n",
    "        self.mask[kernel_shape[0]//2,kernel_shape[1]//2 + (self.mask_type == 'B'):,:,:] = 0\n",
    "        self.mask[kernel_shape[0]//2+1:,:,:,:] = 0\n",
    "\n",
    "        self.mask = tf.convert_to_tensor(self.mask, dtype=tf.float32)\n",
    "        self.mask = tf.Variable(self.mask, trainable=False)\n",
    "        #self.kernel = tf.Variable(self.kernel * self.mask)\n",
    "        self.built = True\n",
    "    \n",
    "    #def call(self, inputs):\n",
    "    #  return super(MaskedConv2D, self).call(inputs)\n",
    "  \n",
    "    '''\n",
    "    the code snippet below is taken from tf.keras convolutional.py\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        outputs = self._convolution_op(inputs, self.kernel * self.mask)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsPuKbngpAFt"
   },
   "outputs": [],
   "source": [
    " class MaskedConv1D(layers.Conv1D):\n",
    "    def __init__(self, *args, mask='B', n_channel=3, mono=False, **kargs):\n",
    "        super(MaskedConv1D, self).__init__(*args,**kargs)\n",
    "        self.mask_type = mask\n",
    "        self.mask = None\n",
    "        self.trainable=True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv1D, self).build(input_shape)\n",
    "        if self.data_format == 'channel_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape.dims[channel_axis].value is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                           'should be defined. Found `None`.')\n",
    "        input_dim = int(input_shape[channel_axis])\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "\n",
    "        self.mask[kernel_shape[0]//2 + (self.mask_type == 'B'):,:,:] = 0.\n",
    "        self.mask = tf.convert_to_tensor(self.mask,dtype=tf.float32)\n",
    "        self.mask = tf.Variable(self.mask, trainable=False)\n",
    "        #self.kernel = tf.Variable(self.kernel*self.mask)\n",
    "        self.built = True\n",
    "    \n",
    "    #def call(self, inputs):\n",
    "    #  return super(MaskedConv1D, self).call(inputs)\n",
    "  \n",
    "    '''\n",
    "    the code snippet below is taken from tf.keras convolutional.py\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        outputs = self._convolution_op(inputs, self.kernel * self.mask)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6YdUdiLSb0B"
   },
   "outputs": [],
   "source": [
    "class RowLSTMCell(layers.AbstractRNNCell):\n",
    "    def __init__(self, hidden_dims, img_size, **kargs):\n",
    "        super(RowLSTMCell, self).__init__(**kargs)\n",
    "        self._hidden_dims = hidden_dims\n",
    "        self._image_size = img_size\n",
    "        self._num_units = self._hidden_dims * self._image_size\n",
    "        self._state_size = self._num_units*2\n",
    "        self._output_size = self._num_units\n",
    "\n",
    "        self.conv_i_s = MaskedConv1D(4 * hidden_dims, 3, mask='B', n_channel=hidden_dims, padding='same')\n",
    "        self.conv_s_s = Conv1D(4 * hidden_dims, 3, padding='same')\n",
    "\n",
    "        self.trainable=True\n",
    "  \n",
    "    def build(self, input_shape):\n",
    "        super(RowLSTMCell, self).build(input_shape)\n",
    "        self.built = True\n",
    "  \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "  \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size\n",
    "  \n",
    "    def call(self, inputs, states):\n",
    "\n",
    "        width = self._image_size\n",
    "        hidden_dims = self._hidden_dims\n",
    "        c_prev = states[0][:,:self._num_units] #(batch, height(width) * hidden_dims)\n",
    "        h_prev = states[0][:,self._num_units:] #(batch, height(width) * hidden_dims)\n",
    "\n",
    "        h_prev = tf.reshape(h_prev, [-1, width, hidden_dims])\n",
    "        inputs = tf.reshape(inputs, [-1, width, hidden_dims])\n",
    "\n",
    "        s_s = tf.transpose(tf.reshape(self.conv_s_s(h_prev), [-1, width, 4, hidden_dims]), perm=[0,2,1,3]) #output_shape == (batch, width, 4*hidden_dims) --reshape & transpose-->(batch, 4, width, hidden_dims)\n",
    "        i_s = tf.transpose(tf.reshape(self.conv_i_s(inputs), [-1, width, 4, hidden_dims]), perm=[0,2,1,3]) #output_shape == (batch, width, 4*hidden_dims) --reshape & transpose-->(batch, 4, width, hidden_dims)\n",
    "\n",
    "        s_s = tf.reshape(s_s,[-1,4 * width * hidden_dims])\n",
    "        i_s = tf.reshape(i_s,[-1,4 * width * hidden_dims])\n",
    "        lstm = tf.sigmoid(s_s+i_s)\n",
    "\n",
    "        i, g, f, o = tf.split(lstm, 4, 1)\n",
    "\n",
    "        c = f * c_prev + i * g\n",
    "        h = tf.multiply(o, tf.tanh(c), name='hid') #그냥 *로 해도되는데, name을 주기 위해서?\n",
    "\n",
    "        new_state = tf.concat([c,h], 1)\n",
    "        return h, new_state\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rU2re8dO2vIm"
   },
   "outputs": [],
   "source": [
    "class PixelRNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, hidden_dims, width, height, channels, layers=1, **kargs):\n",
    "        super(PixelRNN, self).__init__(**kargs)\n",
    "\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._channels = channels\n",
    "        self._hidden_dims = hidden_dims\n",
    "\n",
    "        self.conv1 = MaskedConv2D(hidden_dims, (7,7),n_channel=1, mask='A', padding='same')\n",
    "        if layers > 1:\n",
    "            self.rowlstm = RNN([RowLSTMCell(hidden_dims, width) for _ in range(layers)], return_sequences=True)\n",
    "        else:\n",
    "            self.rowlstm = RNN(RowLSTMCell(hidden_dims, width), return_sequences=True)\n",
    "\n",
    "        #self.conv2 = MaskedConv2D(32, (1,1), mask='B', padding='same', activation='relu')\n",
    "        #self.conv_last = MaskedConv2D(1, (1,1), mask='B', padding='same', activation='relu')\n",
    "        self.conv2 = Conv2D(32, (1,1), padding='same', activation='relu')\n",
    "        self.conv_last = Conv2D(1, (1,1), padding='same')\n",
    "    \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.rowlstm(x)\n",
    "        x = tf.reshape(x, [-1, self._height, self._width, self._hidden_dims])\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv_last(x)\n",
    "        #return tf.reshape(activations.sigmoid(x), [-1, self._width*self._height])\n",
    "        return activations.sigmoid(x)\n",
    "   \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # You need to override this function if you want to use the subclassed model\n",
    "        # as part of a functional-style model.\n",
    "        # Otherwise, this method is optional.\n",
    "        shape_in = tf.TensorShape(input_shape).as_list()\n",
    "        #shape_out = [shape_in[0], shape_in[-1]*shape_in[-2]*shape_in[-3]]\n",
    "\n",
    "        return tf.TensorShape(shape_in)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlDqdTIx4mf4"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIMS = 16\n",
    "LAYERS = 2\n",
    "HEIGHT, WIDTH = (28,28)\n",
    "CHANNELS = 1\n",
    "\n",
    "pixelrnn = PixelRNN(HIDDEN_DIMS,WIDTH,HEIGHT,CHANNELS,LAYERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxANQZiWE40R"
   },
   "source": [
    "It seems like TF Eagermode tracks variables once model is built and build() is called when model is actually called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPlgy4xyE34d"
   },
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "#pixelrnn.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "#              loss='binary_crossentropy',\n",
    "#              )\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "pixelrnn.compile(optimizer=tf.optimizers.RMSprop(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1572113118431,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "NqRjsx6fPiYf",
    "outputId": "993d9d2b-5978-427f-a0cb-a562d5b4710f"
   },
   "outputs": [],
   "source": [
    "model.layers[2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1572111434488,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "OwGD3lBWio63",
    "outputId": "b6627d4b-4f18-4efa-b4fa-52abbefe9d3d"
   },
   "outputs": [],
   "source": [
    "print(pixelrnn.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEbHEyL0jPzR"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='./trained/model_{epoch}.ckpt', mode='min', monitor='val_loss')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16738,
     "status": "error",
     "timestamp": 1572111463666,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "0P_1tAWoGe9q",
    "outputId": "b2ac5bdd-24cb-4447-a5a0-c8ccac0c3984"
   },
   "outputs": [],
   "source": [
    "pixelrnn.fit(train_dataset, verbose=1, validation_data=val_dataset, epochs=5, callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1571761085851,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "e6EZAEFmApg1",
    "outputId": "a12186a0-47f8-4420-abf8-9d48f1021549"
   },
   "outputs": [],
   "source": [
    "pixelrnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkTaIvYQjmGv"
   },
   "source": [
    "Another way of training\n",
    "\n",
    "Using custom train_step decorated with @tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nbz8kwmbUHFM"
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.optimizers.Adam(learning_rate=0.01, beta_1=0.99, epsilon=1e-1)\n",
    "optimizer = tf.optimizers.RMSprop(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hkIhRZ2MpQk"
   },
   "source": [
    "Checkpoint's constructor accepts keyword arguments whose values are types that contain trackable state, such as tf.keras.optimizers.Optimizer implementations, tf.Variable, tf.keras.Layer implementations, or tf.keras.Model implementations. It saves these values with a checkpoint, and maintains a save_counter for numbering checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCWh-3_AMmlk"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(pixelrnn=pixelrnn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiKWda2-N4it"
   },
   "source": [
    "Equivalent to tf.train.latest_checkpoint(directory) where directory is the constructor argument to CheckpointManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OogW6oEgMmwZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint/train'\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8ZGI_a2oqSD"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "  \n",
    "  #if len(targets.shape) > 2:\n",
    "  #  width = targets.shape[-2]\n",
    "  #  targets = tf.reshape(targets, [-1, width*width])\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits_ = pixelrnn(inputs)\n",
    "        #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits_))\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        loss = bce(targets, logits_)\n",
    "    grads = tape.gradient(loss, pixelrnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, pixelrnn.trainable_variables))\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720768,
     "status": "ok",
     "timestamp": 1571840738844,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "dB97gH0Lziap",
    "outputId": "597c2672-e686-44fd-fcd2-99fdd8c053fa"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "loss_trace = []\n",
    "import time\n",
    "for epoch in range(EPOCHS):\n",
    "  \n",
    "    total_loss = 0.0\n",
    "    i=0\n",
    "    epoch_start = time.time()\n",
    "    for x,y in train_dataset:\n",
    "        start=time.time()\n",
    "        loss = train_step(x,y)\n",
    "\n",
    "        total_loss += loss\n",
    "        i += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            if i % 500 == 0:\n",
    "                print('{}% complete'.format(i/30))\n",
    "            else:\n",
    "                print('{}% complete'.format(i/30) ,end=' ')\n",
    "\n",
    "        epoch_elapsed = time.time() - epoch_start\n",
    "        print(\"epoch {} : elapsed: {}\".format(epoch,epoch_elapsed))\n",
    "        print(\"epoch {} : loss: {}\".format(epoch,total_loss))\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "        loss_trace.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwAPjqRaJEQS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "clone keras model\n",
    "\n",
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "new_model = keras.Model.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSV_BtHpCzfS"
   },
   "outputs": [],
   "source": [
    "epoch_to_load = 5\n",
    "chkpoint_path = '/content/drive/My Drive/Colab Notebooks/pixelrnn/model_{}.h5'.format(epoch_to_load)\n",
    "pixelrnn_loaded = keras.models.load_model(chkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vb7Ixu7GyrC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#if you store model in .ckpt format\n",
    "latest = tf.train.latest_checkpoint('/content/drive/My Drive/Colab Notebooks/pixelrnn/')\n",
    "# Create a new model instance\n",
    "pixelrnn_loaded = PixelRNN(HIDDEN_DIMS,WIDTH,HEIGHT,CHANNELS,LAYERS)\n",
    "\n",
    "# Load the previously saved weights\n",
    "pixelrnn_loaded .load_weights(latest)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duhSNYafG0ew"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this is also possible\n",
    "new_model = keras.models.model_from_json(json_config)\n",
    "new_model.load_weights('path_to_my_weights.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uZyCJtgLKpr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate(model, batch=1):\n",
    "    \n",
    "    generate_samples = np.zeros((batch,28,28,1), dtype=np.float32)\n",
    "    import copy\n",
    "    clone = copy.deepcopy(generate_samples)\n",
    "    beg = time.time()\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            generate_samples[:,i,j,0] = binarize(model(generate_samples).numpy())[:,i,j,0]\n",
    "      \n",
    "    elapsed = time.time() - beg\n",
    "    print(\"time taken for generation: {}\".format(elapsed))\n",
    "    return clone, generate_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544047,
     "status": "ok",
     "timestamp": 1571822268729,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "r-_Q8YjD9UbM",
    "outputId": "a0b3d474-9cc4-448b-ef49-335fba5b79b3"
   },
   "outputs": [],
   "source": [
    "org, gen = generate_MNIST(pixelrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1571802972128,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "nWvWARz-1CYj",
    "outputId": "752de1a7-217f-426f-a0fc-139af59504a5"
   },
   "outputs": [],
   "source": [
    "id(org) == id(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1571822656621,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "M1US4FGQOTtR",
    "outputId": "d35ac273-4683-4f6b-ba30-e0a060de9c91"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(tf.squeeze(gen[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbwW3AmJ_M53"
   },
   "outputs": [],
   "source": [
    "def generate_occluded(model, occluded_image, occl_row=None):\n",
    "    if not occl_row:\n",
    "        print(\"Specify the occlusion region by passing occl_row, which indicates the first row index under which an occlusion happens\")\n",
    "  \n",
    "    import copy\n",
    "    clone = copy.deepcopy(occluded_image)\n",
    "  \n",
    "    for i in range(28-occl_row):\n",
    "        for j in range(28):\n",
    "            occluded_image[:,occl_row+i,j,:] = binarize(model(occluded_image).numpy())[:,occl_row+i,j,:]\n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1175,
     "status": "ok",
     "timestamp": 1571802979972,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "NjeVXKO-VJ7j",
    "outputId": "25e78733-8948-4618-9d96-0dd9701ad7db"
   },
   "outputs": [],
   "source": [
    "plt.imshow(tf.squeeze(org[0]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PixelRNN implementaion keras",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
