{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4026,
     "status": "ok",
     "timestamp": 1572161310080,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "FwaM_08ESRRG",
    "outputId": "f05c7a95-dbac-4188-aa93-20fe393ab94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AbstractRNNCell\n",
    "from tensorflow.keras.layers import RNN\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R21uTgXWdcJS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EGGpIwh5E0R"
   },
   "source": [
    "If you want to check if op is run on GPU set following option to be true and run toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1uMmduDb6n8"
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_Pcww9S02Q6"
   },
   "source": [
    "You can skip the cell below since Eager Execution is by default enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4826,
     "status": "ok",
     "timestamp": 1571839966279,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "ov66Cb0nsZfF",
    "outputId": "8030f92b-363a-4969-d2fb-c083c9c7a77b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbjqRp_n18ul"
   },
   "outputs": [],
   "source": [
    "def binarize(images):\n",
    "    return (np.random.uniform(size=images.shape) < images).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4147,
     "status": "ok",
     "timestamp": 1572161318990,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "vFYt5op8zdKH",
    "outputId": "f1c367c5-b49e-457d-ca51-100e6f5f9e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "    pass\n",
    "\n",
    "def mnist_dataset(bsize=100, shuffle_buffer_size=1000):\n",
    "    (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "    x = binarize(np.array(x / 255.0, dtype=np.float32))\n",
    "    x = np.expand_dims(x, -1)\n",
    "    #import copy\n",
    "    #y = copy.deepcopy(x)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, Xval, Y, Yval = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    n_tr = X.shape[0]\n",
    "    n_te = Xval.shape[0]\n",
    "\n",
    "    #trds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    trds = tf.data.Dataset.from_tensor_slices((X, X))\n",
    "    #trds = trds.map(prepare_mnist_features_and_labels)\n",
    "    trds = trds.take(n_tr).shuffle(shuffle_buffer_size).batch(bsize)\n",
    "\n",
    "    #teds = tf.data.Dataset.from_tensor_slices((Xval, Yval))\n",
    "    teds = tf.data.Dataset.from_tensor_slices((Xval, Xval))\n",
    "    #trds = trds.map(prepare_mnist_features_and_labels)\n",
    "    teds = teds.take(n_te).shuffle(shuffle_buffer_size).batch(bsize)\n",
    "\n",
    "    return trds, teds\n",
    "\n",
    "train_dataset, val_dataset = mnist_dataset(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IloFNqJJSbxB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import nn\n",
    "\n",
    "'''\n",
    "grayscale은 쉬운데\n",
    "grayscale부터 해보자!\n",
    "rgb는 내생각에는\n",
    "utils에\n",
    "N, H, W, C --> N,H,W*C로 만들어야할듯\n",
    "반대 operation도! skew참조\n",
    "\n",
    "'''\n",
    "\n",
    "class MaskedConv2D(layers.Conv2D):\n",
    "    def __init__(self, *args, mask='B', n_channel=3, mono=False, **kargs):\n",
    "        super(MaskedConv2D,self).__init__(*args,**kargs)\n",
    "        self.mask_type = mask\n",
    "        self.mask = None\n",
    "        self.trainable=True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv2D, self).build(input_shape)\n",
    "        if self.data_format == 'channel_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape.dims[channel_axis].value is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                           'should be defined. Found `None`.')\n",
    "        input_dim = int(input_shape[channel_axis])\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "\n",
    "        self.mask[kernel_shape[0]//2,kernel_shape[1]//2 + (self.mask_type == 'B'):,:,:] = 0\n",
    "        self.mask[kernel_shape[0]//2+1:,:,:,:] = 0\n",
    "\n",
    "        self.mask = tf.convert_to_tensor(self.mask, dtype=tf.float32)\n",
    "        self.mask = tf.Variable(self.mask, trainable=False)\n",
    "        #self.kernel = tf.Variable(self.kernel * self.mask)\n",
    "        self.built = True\n",
    "    \n",
    "    #def call(self, inputs):\n",
    "    #  return super(MaskedConv2D, self).call(inputs)\n",
    "  \n",
    "    '''\n",
    "    the code snippet below is taken from tf.keras convolutional.py\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        outputs = self._convolution_op(inputs, self.kernel * self.mask)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsPuKbngpAFt"
   },
   "outputs": [],
   "source": [
    " class MaskedConv1D(layers.Conv1D):\n",
    "    def __init__(self, *args, mask='B', n_channel=3, mono=False, **kargs):\n",
    "        super(MaskedConv1D, self).__init__(*args,**kargs)\n",
    "        self.mask_type = mask\n",
    "        self.mask = None\n",
    "        self.trainable=True\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv1D, self).build(input_shape)\n",
    "        if self.data_format == 'channel_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape.dims[channel_axis].value is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                           'should be defined. Found `None`.')\n",
    "        input_dim = int(input_shape[channel_axis])\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "\n",
    "        self.mask[kernel_shape[0]//2 + (self.mask_type == 'B'):,:,:] = 0.\n",
    "        self.mask = tf.convert_to_tensor(self.mask,dtype=tf.float32)\n",
    "        self.mask = tf.Variable(self.mask, trainable=False)\n",
    "        #self.kernel = tf.Variable(self.kernel*self.mask)\n",
    "        self.built = True\n",
    "    \n",
    "    #def call(self, inputs):\n",
    "    #  return super(MaskedConv1D, self).call(inputs)\n",
    "  \n",
    "    '''\n",
    "    the code snippet below is taken from tf.keras convolutional.py\n",
    "    '''\n",
    "    def call(self, inputs):\n",
    "        outputs = self._convolution_op(inputs, self.kernel * self.mask)\n",
    "\n",
    "        if self.use_bias:\n",
    "            if self.data_format == 'channels_first':\n",
    "                if self.rank == 1:\n",
    "                    # nn.bias_add does not accept a 1D input tensor.\n",
    "                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\n",
    "                    outputs += bias\n",
    "                else:\n",
    "                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
    "            else:\n",
    "                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1379,
     "status": "ok",
     "timestamp": 1572100385609,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "4UjBjgGCdC26",
    "outputId": "5978a0d6-2547-4487-b631-115d54f222e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36, shape=(2, 3, 3), dtype=int64, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9]],\n",
       "\n",
       "       [[10, 11, 12],\n",
       "        [13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(np.arange(1,19,1).reshape(2,3,3))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPIhxNfAbnvX"
   },
   "outputs": [],
   "source": [
    "# this code is inspired by https://github.com/carpedm20/pixel-rnn-tensorflow/blob/master/ops.py\n",
    "\n",
    "def skew(inputs, scope='skew'):\n",
    "    with tf.name_scope(scope):\n",
    "        batch, height, width, channels = inputs.shape\n",
    "\n",
    "        rows = tf.split(inputs, height, 1) #(batch, 1, width, channel) * height\n",
    "        skewed_rows = []\n",
    "\n",
    "        for idx, row in enumerate(rows):\n",
    "            skewed_row  = tf.pad(tf.squeeze(row, 1), [[0,0], [idx, width-idx-1], [0,0]])\n",
    "            skewed_rows.append(skewed_row)\n",
    "\n",
    "        result = tf.stack(skewed_rows, axis=1)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def unskew(inputs, scope='unskew'):\n",
    "    with tf.name_scope(scope):\n",
    "        batch, height, width, channels = inputs.shape\n",
    "        width = (width+1)//2\n",
    "\n",
    "        rows = tf.split(inputs, height, 1) #(batch, 1, 2*width-1, channel) * height\n",
    "        unskewed_rows = []\n",
    "\n",
    "        for idx, row in enumerate(rows):\n",
    "            unskewed_row = tf.slice(tf.squeeze(row, 1), [0, idx, 0], [-1, width, -1])\n",
    "            unskewed_rows.append(unskewed_row)\n",
    "\n",
    "        result = tf.stack(unskewed_rows, axis=1)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1572163805268,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "ENgrEAxNbpqX",
    "outputId": "ba2b79b0-4759-4bf5-81af-f53543f892dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40012, shape=(3, 5), dtype=int64, numpy=\n",
       "array([[ 1,  3,  5,  0,  0],\n",
       "       [ 0,  7,  9, 11,  0],\n",
       "       [ 0,  0, 13, 15, 17]])>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(np.arange(1,37,1).reshape(2,3,3,2))\n",
    "skew(t)[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-Eg-RywbMxT"
   },
   "outputs": [],
   "source": [
    "class BiLSTMCell(layers.AbstractRNNCell):\n",
    "    def __init__(self, hidden_dims, height, *args, **kargs):\n",
    "        super(BiLSTMCell, self).__init__(*args, **kargs)\n",
    "        self._hidden_dims = hidden_dims\n",
    "        self._height = height\n",
    "        self._num_units = self._hidden_dims * self._height\n",
    "        self._state_size = self._num_units * 2\n",
    "        self._output_size = self._num_units\n",
    "\n",
    "        self.conv_i_s = MaskedConv1D(4 * hidden_dims, 1, mask='B', n_channel=hidden_dims, padding='same')\n",
    "        self.conv_s_s = Conv1D(4 * hidden_dims, 2, padding='same')\n",
    "  \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._state_size\n",
    "  \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size\n",
    "  \n",
    "  \n",
    "    def call(self, inputs, states):\n",
    "    \n",
    "        height = self._height\n",
    "        hidden_dims = self._hidden_dims\n",
    "        c_prev = states[0][:,:self._num_units] #(batch, height * hidden_dims)\n",
    "        h_prev = states[0][:,self._num_units:] #(batch, height * hidden_dims)\n",
    "\n",
    "        h_prev = tf.reshape(h_prev, [-1, height, hidden_dims])\n",
    "        inputs = tf.reshape(inputs, [-1, height, hidden_dims])\n",
    "\n",
    "        s_s = tf.transpose(tf.reshape(self.conv_s_s(h_prev), [-1, height, 4, hidden_dims]), perm=[0,2,1,3]) #output_shape == (batch, height, 4*hidden_dims) --reshape & transpose-->(batch, 4, height, hidden_dims)\n",
    "        i_s = tf.transpose(tf.reshape(self.conv_i_s(inputs), [-1, height, 4, hidden_dims]), perm=[0,2,1,3]) #output_shape == (batch, height, 4*hidden_dims) --reshape & transpose-->(batch, 4, height, hidden_dims)\n",
    "\n",
    "        s_s = tf.reshape(s_s,[-1,4 * height * hidden_dims])\n",
    "        i_s = tf.reshape(i_s,[-1,4 * height * hidden_dims])\n",
    "        lstm = tf.sigmoid(s_s+i_s)\n",
    "\n",
    "        i, g, f, o = tf.split(lstm, 4, 1)\n",
    "\n",
    "        c = f * c_prev + i * g\n",
    "        h = tf.multiply(o, tf.tanh(c), name='hid') #그냥 *로 해도되는데, name을 주기 위해서?\n",
    "\n",
    "        new_state = tf.concat([c,h], 1)\n",
    "        return h, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-51pofPwbQt"
   },
   "outputs": [],
   "source": [
    "def reverse(inputs):\n",
    "  #inputs == (batch, height, width, channels)\n",
    "  return tf.reverse(inputs, axis=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1572163808218,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "Uw0HugXvJbFu",
    "outputId": "3aafad5e-7e26-4574-bb68-cea0b5c1051c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40034, shape=(3, 5), dtype=int64, numpy=\n",
       "array([[ 5,  3,  1,  0,  0],\n",
       "       [ 0, 11,  9,  7,  0],\n",
       "       [ 0,  0, 17, 15, 13]])>"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(np.arange(1,37,1).reshape(2,3,3,2))\n",
    "skew(reverse(t))[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Nj-2M-AwBg4"
   },
   "outputs": [],
   "source": [
    "class DiagonalBiLSTM(tf.keras.Model):\n",
    "    def __init__(self, hidden_dims, width, height, channels, layers=1, *args, **kargs):\n",
    "        super(DiagonalBiLSTM, self).__init__(*args, **kargs)\n",
    "\n",
    "        self._width = width\n",
    "        self._height = height\n",
    "        self._channels = channels\n",
    "        self._hidden_dims = hidden_dims    \n",
    "\n",
    "        self.conv7_7 = MaskedConv2D(hidden_dims, (7,7), n_channel=1, mask='A', padding='same')\n",
    "        if layers > 1:\n",
    "            self.bilstm = RNN([BiLSTMCell(hidden_dims, height) for _ in range(layers)], return_sequences=True)\n",
    "            self.bilstm_reverse = RNN([BiLSTMCell(hidden_dims, height) for _ in range(layers)], return_sequences=True)\n",
    "        else:\n",
    "            self.bilstm = RNN(BiLSTMCell(hidden_dims, height), return_sequences=True)\n",
    "            self.bilstm_reverse = RNN(BiLSTMCell(hidden_dims, height), return_sequences=True)\n",
    "\n",
    "        self.conv_1_32 = Conv2D(32, (1,1), padding='same', activation='relu')\n",
    "        self.conv_1_1 = Conv2D(1, (1,1), padding='same')\n",
    "    \n",
    "      \n",
    "    def call(self, x):\n",
    "        #x --> (batch, height, width, channels)\n",
    "        batch, height, width, channels = x.shape\n",
    "        hidden_dims = self._hidden_dims\n",
    "        out = self.conv7_7(x) # --> (batch, height, width, hidden_dims)\n",
    "        out_reversed = reverse(out)  # --> (batch, height, width, hidden_dims)\n",
    "\n",
    "        out_forward = tf.reshape(tf.transpose(skew(out), perm=[0,2,1,3]), [-1, 2*width-1, height*hidden_dims])# --> (batch, 2*width-1, height*hidden_dims)\n",
    "        out_reversed = tf.reshape(tf.transpose(skew(out_reversed), perm=[0,2,1,3]), [-1, 2*width-1, height*hidden_dims]) # --> (batch, 2*width-1, height*hidden_dims)\n",
    "\n",
    "\n",
    "        out_forward = tf.transpose(tf.reshape(self.bilstm(out_forward), [-1, self._width*2-1, self._height, self._hidden_dims]), perm=[0,2,1,3]) #(batch, 2*width-1, height*hidden_dims) --> (batch, height, 2*width-1, hid)\n",
    "        out_reverse = tf.transpose(tf.reshape(reverse(self.bilstm_reverse(out_reversed)), [-1, self._width*2-1, self._height, self._hidden_dims]), perm=[0,2,1,3])\n",
    "\n",
    "        out_forward = unskew(out_forward)\n",
    "\n",
    "        out_reverse = unskew(out_reverse) #(batch, height, width, hidden_dims)\n",
    "\n",
    "        out_reverse_shifted = tf.slice(tf.pad(out_reverse, [[0,0],[0,0],[0,1],[0,0]]), [0,0,1,0], [-1, -1, -1, -1])\n",
    "\n",
    "        out = out_forward + out_reverse - out_reverse_shifted\n",
    "\n",
    "        out = self.conv_1_32(out)\n",
    "        out = self.conv_1_1(out)\n",
    "\n",
    "        return activations.sigmoid(out)\n",
    "    \n",
    "  \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlDqdTIx4mf4"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIMS = 16\n",
    "LAYERS = 2\n",
    "HEIGHT, WIDTH = (28,28)\n",
    "CHANNELS = 1\n",
    "\n",
    "bilstm = DiagonalBiLSTM(HIDDEN_DIMS,WIDTH,HEIGHT,CHANNELS,LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2047,
     "status": "ok",
     "timestamp": 1572163911730,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "Lv4Als7jQF-I",
    "outputId": "b2b4b5b3-e8a4-4369-9f3c-15fc6f62671f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=99528, shape=(16, 28, 28, 1), dtype=float32, numpy=\n",
       "array([[[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371952],\n",
       "         [0.4637195 ],\n",
       "         [0.4512056 ]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.4637192 ],\n",
       "         [0.46371925],\n",
       "         [0.45281506]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46371898],\n",
       "         [0.46371913],\n",
       "         [0.4528919 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.46372488],\n",
       "         [0.4637249 ],\n",
       "         [0.4637249 ],\n",
       "         ...,\n",
       "         [0.46371084],\n",
       "         [0.46371508],\n",
       "         [0.45287946]],\n",
       "\n",
       "        [[0.4640932 ],\n",
       "         [0.46409324],\n",
       "         [0.46409327],\n",
       "         ...,\n",
       "         [0.4640852 ],\n",
       "         [0.46408817],\n",
       "         [0.45327845]],\n",
       "\n",
       "        [[0.46793586],\n",
       "         [0.4679359 ],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.46793595],\n",
       "         [0.46793595],\n",
       "         [0.45814365]]],\n",
       "\n",
       "\n",
       "       [[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371928],\n",
       "         [0.4637193 ],\n",
       "         [0.4512055 ]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.46371886],\n",
       "         [0.463719  ],\n",
       "         [0.45281467]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46389186],\n",
       "         [0.4635837 ],\n",
       "         [0.45284545]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4637245 ],\n",
       "         [0.4637246 ],\n",
       "         [0.46372473],\n",
       "         ...,\n",
       "         [0.46369755],\n",
       "         [0.4637234 ],\n",
       "         [0.45286393]],\n",
       "\n",
       "        [[0.4640932 ],\n",
       "         [0.46409327],\n",
       "         [0.46409327],\n",
       "         ...,\n",
       "         [0.4640933 ],\n",
       "         [0.4640933 ],\n",
       "         [0.45328173]],\n",
       "\n",
       "        [[0.4679359 ],\n",
       "         [0.4679359 ],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.46793595],\n",
       "         [0.46793595],\n",
       "         [0.45814365]]],\n",
       "\n",
       "\n",
       "       [[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371955],\n",
       "         [0.46371952],\n",
       "         [0.45120564]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.46371943],\n",
       "         [0.46371946],\n",
       "         [0.4528152 ]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46371928],\n",
       "         [0.4637193 ],\n",
       "         [0.4528922 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.46372485],\n",
       "         [0.46372488],\n",
       "         [0.4637249 ],\n",
       "         ...,\n",
       "         [0.4637228 ],\n",
       "         [0.46372366],\n",
       "         [0.45288435]],\n",
       "\n",
       "        [[0.46409324],\n",
       "         [0.46409327],\n",
       "         [0.46409327],\n",
       "         ...,\n",
       "         [0.4640926 ],\n",
       "         [0.4640929 ],\n",
       "         [0.45328152]],\n",
       "\n",
       "        [[0.46793586],\n",
       "         [0.4679359 ],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.4679358 ],\n",
       "         [0.4679359 ],\n",
       "         [0.45814362]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371952],\n",
       "         [0.4637195 ],\n",
       "         [0.4512056 ]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.46371913],\n",
       "         [0.4637192 ],\n",
       "         [0.452815  ]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46371847],\n",
       "         [0.46373823],\n",
       "         [0.4528682 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.46372512],\n",
       "         [0.46372497],\n",
       "         [0.46370494],\n",
       "         ...,\n",
       "         [0.46369967],\n",
       "         [0.46370253],\n",
       "         [0.45286876]],\n",
       "\n",
       "        [[0.4640932 ],\n",
       "         [0.4640932 ],\n",
       "         [0.4640932 ],\n",
       "         ...,\n",
       "         [0.464084  ],\n",
       "         [0.46408752],\n",
       "         [0.45327803]],\n",
       "\n",
       "        [[0.46793586],\n",
       "         [0.4679359 ],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.46793598],\n",
       "         [0.46793598],\n",
       "         [0.45814365]]],\n",
       "\n",
       "\n",
       "       [[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371955],\n",
       "         [0.46371952],\n",
       "         [0.45120564]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.46371943],\n",
       "         [0.46371946],\n",
       "         [0.45281523]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46371946],\n",
       "         [0.46371946],\n",
       "         [0.45289236]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.46372485],\n",
       "         [0.46372488],\n",
       "         [0.4637249 ],\n",
       "         ...,\n",
       "         [0.46372384],\n",
       "         [0.46372318],\n",
       "         [0.45288754]],\n",
       "\n",
       "        [[0.46409324],\n",
       "         [0.46409327],\n",
       "         [0.46409327],\n",
       "         ...,\n",
       "         [0.4640852 ],\n",
       "         [0.4640878 ],\n",
       "         [0.45327953]],\n",
       "\n",
       "        [[0.46793586],\n",
       "         [0.4679359 ],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.46792752],\n",
       "         [0.46793073],\n",
       "         [0.45814115]]],\n",
       "\n",
       "\n",
       "       [[[0.48980787],\n",
       "         [0.47708803],\n",
       "         [0.4704276 ],\n",
       "         ...,\n",
       "         [0.46371955],\n",
       "         [0.46371952],\n",
       "         [0.45120564]],\n",
       "\n",
       "        [[0.4771138 ],\n",
       "         [0.4702713 ],\n",
       "         [0.4668972 ],\n",
       "         ...,\n",
       "         [0.46371943],\n",
       "         [0.46371946],\n",
       "         [0.45281523]],\n",
       "\n",
       "        [[0.47024828],\n",
       "         [0.46688816],\n",
       "         [0.46524182],\n",
       "         ...,\n",
       "         [0.46371907],\n",
       "         [0.46371862],\n",
       "         [0.4528906 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.46372485],\n",
       "         [0.4637249 ],\n",
       "         [0.4637249 ],\n",
       "         ...,\n",
       "         [0.46372458],\n",
       "         [0.46372473],\n",
       "         [0.45288485]],\n",
       "\n",
       "        [[0.46409324],\n",
       "         [0.46409327],\n",
       "         [0.46409327],\n",
       "         ...,\n",
       "         [0.46409306],\n",
       "         [0.46409315],\n",
       "         [0.45328164]],\n",
       "\n",
       "        [[0.46793586],\n",
       "         [0.46793592],\n",
       "         [0.46793592],\n",
       "         ...,\n",
       "         [0.46793598],\n",
       "         [0.46793598],\n",
       "         [0.45814365]]]], dtype=float32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilstm(next(iter(train_dataset))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxANQZiWE40R"
   },
   "source": [
    "It seems like TF Eagermode tracks variables once model is built and build() is called when model is actually called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPlgy4xyE34d"
   },
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "#pixelrnn.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "#              loss='binary_crossentropy',\n",
    "#              )\n",
    "\n",
    "# The compile step specifies the training configuration.\n",
    "bilstm.compile(optimizer=tf.optimizers.RMSprop(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1572163914781,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "OwGD3lBWio63",
    "outputId": "b0be5af6-5e33-4841-c8f7-2184128ec615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(bilstm.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MEbHEyL0jPzR"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/My Drive/Colab Notebooks/bilstm/model_{epoch}.ckpt', mode='min', monitor='val_loss')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14460,
     "status": "error",
     "timestamp": 1572028222931,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "0P_1tAWoGe9q",
    "outputId": "94ea4387-12c0-4ab2-d2d6-26817e56a9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 1186s 395ms/step - loss: 0.0244 - val_loss: 0.0000e+00\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 1166s 389ms/step - loss: 1.1211e-04 - val_loss: 1.1274e-04\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 1169s 390ms/step - loss: 1.0908e-04 - val_loss: 1.0677e-04\n",
      "Epoch 4/5\n",
      " 208/3000 [=>............................] - ETA: 17:17 - loss: 9.5428e-05"
     ]
    }
   ],
   "source": [
    "bilstm.fit(train_dataset, verbose=1, validation_data=val_dataset, epochs=5, callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDQfsN_Wb6YT"
   },
   "outputs": [],
   "source": [
    "check_input = next(iter(train_dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1571815544739,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "pURxgvGJcPbh",
    "outputId": "5e46aa1d-2ed6-48ad-d93f-2a67aebf56d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 28, 28, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1571815546740,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "NS0v8krfcThd",
    "outputId": "77a0683b-9646-486e-a153-0b38cc8b3a85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd93f9b3748>"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfxK4qK7ZRGfoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(check_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1571761085851,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "e6EZAEFmApg1",
    "outputId": "a12186a0-47f8-4420-abf8-9d48f1021549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pixel_rnn_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masked_conv2d_6 (MaskedConv2 multiple                  3168      \n",
      "_________________________________________________________________\n",
      "rnn_3 (RNN)                  multiple                  259840    \n",
      "_________________________________________________________________\n",
      "masked_conv2d_7 (MaskedConv2 multiple                  65        \n",
      "=================================================================\n",
      "Total params: 263,073\n",
      "Trainable params: 175,457\n",
      "Non-trainable params: 87,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixelrnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkTaIvYQjmGv"
   },
   "source": [
    "Another way of training\n",
    "\n",
    "Using custom train_step decorated with @tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nbz8kwmbUHFM"
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.optimizers.Adam(learning_rate=0.01, beta_1=0.99, epsilon=1e-1)\n",
    "optimizer = tf.optimizers.RMSprop(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hkIhRZ2MpQk"
   },
   "source": [
    "Checkpoint's constructor accepts keyword arguments whose values are types that contain trackable state, such as tf.keras.optimizers.Optimizer implementations, tf.Variable, tf.keras.Layer implementations, or tf.keras.Model implementations. It saves these values with a checkpoint, and maintains a save_counter for numbering checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCWh-3_AMmlk"
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(pixelrnn=pixelrnn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiKWda2-N4it"
   },
   "source": [
    "Equivalent to tf.train.latest_checkpoint(directory) where directory is the constructor argument to CheckpointManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OogW6oEgMmwZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoint/train'\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8ZGI_a2oqSD"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, targets):\n",
    "\n",
    "    #if len(targets.shape) > 2:\n",
    "    #  width = targets.shape[-2]\n",
    "    #  targets = tf.reshape(targets, [-1, width*width])\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits_ = pixelrnn(inputs)\n",
    "        #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=targets, logits=logits_))\n",
    "        bce = tf.keras.losses.BinaryCrossentropy()\n",
    "        loss = bce(targets, logits_)\n",
    "    grads = tape.gradient(loss, pixelrnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, pixelrnn.trainable_variables))\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720768,
     "status": "ok",
     "timestamp": 1571840738844,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "dB97gH0Lziap",
    "outputId": "597c2672-e686-44fd-fcd2-99fdd8c053fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3333333333333335% complete 6.666666666666667% complete 10.0% complete 13.333333333333334% complete 16.666666666666668% complete\n",
      "20.0% complete 23.333333333333332% complete 26.666666666666668% complete 30.0% complete 33.333333333333336% complete\n",
      "36.666666666666664% complete 40.0% complete 43.333333333333336% complete 46.666666666666664% complete 50.0% complete\n",
      "53.333333333333336% complete 56.666666666666664% complete 60.0% complete 63.333333333333336% complete 66.66666666666667% complete\n",
      "70.0% complete 73.33333333333333% complete 76.66666666666667% complete 80.0% complete 83.33333333333333% complete\n",
      "86.66666666666667% complete 90.0% complete 93.33333333333333% complete 96.66666666666667% complete 100.0% complete\n",
      "epoch 0 : elapsed: 720.024587392807\n",
      "epoch 0 : loss: 709.5159301757812\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "loss_trace = []\n",
    "import time\n",
    "for epoch in range(EPOCHS):\n",
    "  \n",
    "    total_loss = 0.0\n",
    "    i=0\n",
    "    epoch_start = time.time()\n",
    "    for x,y in train_dataset:\n",
    "        start=time.time()\n",
    "        loss = train_step(x,y)\n",
    "\n",
    "        total_loss += loss\n",
    "        i += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            if i % 500 == 0:\n",
    "                print('{}% complete'.format(i/30))\n",
    "            else:\n",
    "                print('{}% complete'.format(i/30) ,end=' ')\n",
    "\n",
    "        epoch_elapsed = time.time() - epoch_start\n",
    "        print(\"epoch {} : elapsed: {}\".format(epoch,epoch_elapsed))\n",
    "        print(\"epoch {} : loss: {}\".format(epoch,total_loss))\n",
    "\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "        loss_trace.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwAPjqRaJEQS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "clone keras model\n",
    "\n",
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "new_model = keras.Model.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSV_BtHpCzfS"
   },
   "outputs": [],
   "source": [
    "epoch_to_load = 5\n",
    "chkpoint_path = '/content/drive/My Drive/Colab Notebooks/pixelrnn/model_{}.h5'.format(epoch_to_load)\n",
    "pixelrnn_loaded = keras.models.load_model(chkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vb7Ixu7GyrC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#if you store model in .ckpt format\n",
    "latest = tf.train.latest_checkpoint('/content/drive/My Drive/Colab Notebooks/pixelrnn/')\n",
    "# Create a new model instance\n",
    "pixelrnn_loaded = PixelRNN(HIDDEN_DIMS,WIDTH,HEIGHT,CHANNELS,LAYERS)\n",
    "\n",
    "# Load the previously saved weights\n",
    "pixelrnn_loaded .load_weights(latest)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duhSNYafG0ew"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this is also possible\n",
    "new_model = keras.models.model_from_json(json_config)\n",
    "new_model.load_weights('path_to_my_weights.h5')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uZyCJtgLKpr"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate(model, batch=1):\n",
    "    \n",
    "    generate_samples = np.zeros((batch,28,28,1), dtype=np.float32)\n",
    "    import copy\n",
    "    clone = copy.deepcopy(generate_samples)\n",
    "    beg = time.time()\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            generate_samples[:,i,j,0] = binarize(model(generate_samples).numpy())[:,i,j,0]\n",
    "      \n",
    "    elapsed = time.time() - beg\n",
    "    print(\"time taken for generation: {}\".format(elapsed))\n",
    "    return clone, generate_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544047,
     "status": "ok",
     "timestamp": 1571822268729,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "r-_Q8YjD9UbM",
    "outputId": "a0b3d474-9cc4-448b-ef49-335fba5b79b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543.0113894939423\n"
     ]
    }
   ],
   "source": [
    "org, gen = generate_MNIST(pixelrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1571802972128,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "nWvWARz-1CYj",
    "outputId": "752de1a7-217f-426f-a0fc-139af59504a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(org) == id(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1571822656621,
     "user": {
      "displayName": "이희찬",
      "photoUrl": "",
      "userId": "06255163499262544080"
     },
     "user_tz": -540
    },
    "id": "M1US4FGQOTtR",
    "outputId": "d35ac273-4683-4f6b-ba30-e0a060de9c91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5be63ca278>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(tf.squeeze(gen[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LbwW3AmJ_M53"
   },
   "outputs": [],
   "source": [
    "def generate_occluded(model, occluded_image, occl_row=None):\n",
    "    if not occl_row:\n",
    "        print(\"Specify the occlusion region by passing occl_row, which indicates the first row index under which an occlusion happens\")\n",
    "  \n",
    "    import copy\n",
    "    clone = copy.deepcopy(occluded_image)\n",
    "  \n",
    "    for i in range(28-occl_row):\n",
    "        for j in range(28):\n",
    "            occluded_image[:,occl_row+i,j,:] = binarize(model(occluded_image).numpy())[:,occl_row+i,j,:]\n",
    "    \n",
    "    return clone, occluded_image\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PixelRNN BiLSTM keras",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
